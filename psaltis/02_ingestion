----------------------------------------------------------------------------
|  CHAPTER 2 - DATA INGESTION                                              |
----------------------------------------------------------------------------

- Common Interaction Patterns

    - Request/Response Pattern

        - Client sends request to service, service sends a response

        - Drawback is client has to sit and wait for synchronous response

        - Solution #1: Client-side half async = client makes requests, continues and gets 
            asynchronous responses later (used by web browsers)

        - Solution #2: Service-side half async = service receives request from client, delegates
            work to be done, then responds to client when work is finished (makes services
            much more scalable)

        - Solution #3: Full async = both client and service perform their work asynchronously


    - Request/Acknowledge Pattern

        - Sometimes, you don't need a response from a service, just an acknowledgment of receipt.

        - Often, the acknowledgment includes data (like an id) that can be used to make subsequent 
            requests, like check the status of the request.


    - Publish/Subscribe Pattern

        - Producers publish messages to a broker on a topic.  Next, the message is sent to all
            consumers subscribed to the topic.

        - With some technologies, published messages are pushed to subscribers.  In other cases, the
            subscribers pull for them.


    - One-Way Pattern

        - This is the 'fire and forget' pattern, where the system making the request doesn't need a
            response at all.  This is useful when the client either doesn't have the resources or the
            need to process a response.

        - For example, services emitting metrics to a monitoring service.


    - Stream Pattern

        - In this case, the collection tier is a client, pulling data in from a streaming source.
            We can have a stream as input and a stream as output.

        - Unlike the other patterns, we don't need to find clients to connect to send requests to 
            our service.  We connect to and process the data from the stream source.

        - For instance, we connect to a Meetup.com feed that sends a JSON event each time someone 
            RSVPs to a meetup.  In this case, a single long-lived HTTP connection is established,
            and data is subsequently streamed back to your browser until you end the HTTP
            connection.



- Scaling the Interaction Patterns

    - The request/resonse pattern is very scalable, because requests are stateless and we can
        easily horizontally scale a service.  In fact, cloud providers offer autoscalers that will
        scale a service up or down based on demand.  This approach requires a load balacer.


    - With many streaming protocols (for instance, the Meetup.com RSVP stream above), there is a
        direct and persistent connection between the client and service.

      This can lead to one client doing all the ingestion while the others sit idle.  There are 2
        possible solutions for scaling up our streaming collection:

        1. Scale up the number of concurrent collection nodes
        2. Add a buffering layer, and have collection nodes pull from that



- Fault Tolerance

    - At some point, our collection nodes will fail.  Depending on the business, in many cases it is
        not OK to lose data.  So, we want to recover as if a crash never occurred.


    - The 2 primary approaches to implementing fault tolerance:

        1. Checkpointing
        2. Logging



- Checkpointing

    - Checkpoint-based protocols have the following characteristics:

        1. Global Snapshot = a snapshot of the global state of the whole system has to be regularly
                               saved to storage somewhere

        2. Potential for data loss = only recoverable up to checkpoint time, any messages processed
                                       afterward are lost


    - Since streaming systems are composed of many layers and different technologies, checkpointing
        is not a good match for them.  It is useful in many other contexts, however.



- Logging Protocols

    - The idea behind logging is that if a message can be replayed, the system can reach a global
        consistent state without the need for a global snapshot.


    - Each tier in the system independently records all messages it receives and plays them back
        after a crash.  This way we can add fault tolerance to the collection tier without worrying
        about maintaining global state.


    - There are 2 classic techniques for this:

        1. Receiver-based message logging (RBML) = concerned with protecting data the node is receiving

        2. Sender-based message logging (SBML) = concerned with protecting the data sent to the next tier

      And there is also a hybrid message logging (HML) technique.



- Receiver-Based Message Logging

    - The RBML technique involves synchronously writing every received message to stable storage 
        before any action is taken on it.

        1. A message is sent from a data producer (any client)

        2. The RBML logger gets the message and sends it to storage

        3. The message is written to storage

        4. The message then proceeds through for any further processing (enrichment, filtering, routing)

        5. The message is sent to the message queueing tier


    - Obviously, this carries a performance cost on the throughput of our collection.


    - In a crash, 

        1. Incoming messages to this collection node are stopped.  It will be taken out of rotation
             by the load balancer.

        2. The RBML logger reads messages that have not been processed from stable storage and sends
             them through the rest of the node logic as if nothing has happened.

        3. After all pending messages are processed, the node is considered restored and can be put
             back into rotation.



- Sender-Based Message Logging

    - The SBML technique involves writing the message to stable storage before it is sent.  Whereas
        RBML technique is to protect us from ourselves, SBML is to protect us from the next tier.


    - In this case, the data we are recording has already been processed by our collection tier.


    - During recovery, we need to know whether the next tier has already processed the message we
        are replaying.  We can do that a few different ways:

        1. Use a message queueing tier that returns an acknowledgment that it received the message.
             With this acknowledgment, we can either mark the message as replayed in stable storage
             or delete it because we no longer need it.

        2. If we use a queueing technology that doesn't send acknowledgments, we may be forced to 
             just delete it if the sending appeared successful.



- Hybrid Message Logging

    - We'll be protected against data loss by using both RBML and SBML, but we'll pay a steep 
        performance penalty.  Hybrid message logging is designed to reduce this cost.  


    - One thing we can do is consolidate the 2 stable storage instances into a single instance.


    - The other thing we can do is write to storage asynchronously, but that adds to the 
        implementation complexity.