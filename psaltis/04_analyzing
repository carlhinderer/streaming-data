----------------------------------------------------------------------------
|  CHAPTER 4 - ANALYZING STREAMING DATA                                    |
----------------------------------------------------------------------------

- In-flight Data Analysis

    - In-flight data is all the tuples in the system, from the source to the output to a client.
        It is always in motion and never at rest (never persisted to durable storage).


    - In a traditional DBMS-based system (ie RDBMS, Hadoop, HBase, Cassandra, etc), data is at rest,
        and we query it for answers.  

      In streaming systems, this is turned on its head.  Data moves through the queries.  This is
        called the 'continuous query model', meaning that the query is constantly being evaluated
        as new data arrives.


    - In a streaming system, a user (or application) registers a query that is executed every time
        data arrives or at a predetermined time interval.  The result of the query is then pushed to
        the client.



- Examples of Problems Solved By Streaming Analysis Tier

    - Tracking behavior - Provide personalized advertising based on a customer's location, the weather,
        and their previous buying habits.


    - Improving traffic safety and efficiency - Get real-time traffic data from sensors, analyze
        traffic data to solve traffic problems.


    - Real-time fraud analysis - US fraud losses on credit cards have declined 70% as a percentage of
        credit card sales since real-time analytics were deployed.



- Distributed Stream Processing Architecture

    - At some point, the velocity and volume of data make it impossible to process on a single
        computer, and we need a distributed architecture.


    - All of the streaming platforms have 3 common parts:

        1. A component that your streaming application is submitted to.  Your application is sent
             to a node in the cluster that executes your application.

        2. Separate nodes in the cluster execute your streaming algorithms.

        3. Data sources the are input to the streaming algorithms.



- Common Architectural Pieces

    - Application driver - With some streaming systems, this defines your streaming and communicates
        with the streaming manager.  With Spark Streaming, the driver submits your job to the
        streaming manager, may collect results at the end, and controls the lifetime of your job.


    - Streaming manager - Has responsibility of getting your streaming job to the stream processors.
        In some cases, it will control or request the resources required by the stream processors.


    - Stream processor - Place where the jobs run.


    - Data sources - Input and potentially output of streaming jobs.



- Apache Spark Streaming

    - Apache Spark has become the de facto platform for general-purpose distributed computation.
        It has support for the Java, Scala, Python, and R languages.  

        Spark Streaming  |  MLib  |  GraphX  |  SparkSQL
        ------------------------------------------------
                        Apache Spark


    - The Spark 'StreamingContext' client contains all the logic to keep track of incoming data,
        set up the streaming jobs, schedule them on Spark workers, and execute the jobs.


        Your Program
        (contains Spark StreamingContext)   <-->  Spark Worker  <-->  Data Source


    - A 'job' in Spark Streaming is the loic of your program that's bundled up and passed to Spark
        workers.  This is similar to the concept of a job with Hadoop MapReduce workers.



- Apache Storm

    - Apache Storm is a tuple-at-a-time stream-processing framework designed for real-time processing
        of data streams.

        
        Your Program  ->  Nimbus (master node)  <-->  Supervisor  <-->  Data sources



- Apache Flink

    - Apache Flink is a stream first framework, where everything is viewed as a stream.


    - A Flink program contains 2 fundamental building blocks:

        1. Stream = an intermediate result as the data flows from sink to sink

        2. Transformation = operation that takes stream as input and produces one or more streams
                              as output


    - When an application is composed of these components and is executed in Flink, it is considered
        a streaming 'dataflow'.

        Your Program
        (contains Flink client)  <-->  JobManager (master)  <-->  TaskManager (worker)



- Apache Samza

    - Apache Samza provides a stage-wise stream-processing framework using Apache Yarn and Apache
        Kafka.


    - YARN manages all the resources (CPU, memory, disk, network, etc.) for all applications running
        on a cluster of computers.  Kafka is used as a high-speed data store that our streaming
        tasks will read from and write to.



- Message Delivery Semantics

    - Remember, there are 3 different types of delivery guarantees:

        1. At most once
        2. At least once
        3. Exactly once


    - We can consider 2 possible failure scenarios:

        1. a message gets dropped between stream processors
        2. the stream processor crashes


    - With 'at most once', our logic is very simple.  If a message is dropped or a processor crashes,
        we don't worry about it.


    - With 'at least once', a processor must keep track of every message that was sent and whether
        an acknowledgment was received.  If the stream manager determines the message wasn't 
        processed, it will be re-sent.

      Note that in this case, a message might be sent multiple times.  Therefore, your streaming job
        must be idempotent.  We often need to design this into our streaming jobs to handle the
        duplicate messages situation.


    - For 'exactly once', in addition to keeping track of all the messages sent, we must also detect
        and ignore duplicates.  Using this guarantee level makes writing streaming jobs easier, since
        they no longer have to be idempotent.


    - Which level of delivery guarantee should we pick to solve a given business problem.  Start
        with the least complex guarantee and work backwards from there.  Can our system still
        function correctly if some data is missing?



- State Management

    - The state management facilities provided by various systems naturally vary in complexity from

         Low (In memory)
         to
         High (Replicated, queryable, persistent storage)


    - The low complexity facilities will help you recover in case of a failure.  The high complexity
        facilities might have more advance features, like the ability to join historical streams
        together.



- Fault Tolerance

    - If there is a problem with an incoming stream of data, our stream processing framework must
        respond gracefully and not fail.


    - If a stream processor fails, the streaming manager must take steps to restart the processor
        or move the processing to a different machine.


    - If the streaming manager fails, the streaming system must be able to restart once a new
        manager is started.


    - We can protect against data loss by replicating the state of computation onto different
        stream processors.  If we can tolerate k defaults, we are said to have a
        'k-fault tolerant' system.

      There are 2 common approaches a system may take toward replication and coordination:

        1. State machine
        2. Rollback recovery


    - With the 'state machine' approach, the stream manager replicates the streaming job on 
        independent nodes and coordinates the replicas by sending the input in the same order
        to all.  This approach requires extra resources, but allows for quick failover.


    - With the 'rollback recovery' approach, the stream processor periodically packages the
        state of computation into a 'checkpoint', which it copies to a different stream processor
        node or just to disk somewhere.  If a stream processor fails, the stream manager must
        reconstruct the state from the most recent checkpoint and replay all transactions in the
        log since.